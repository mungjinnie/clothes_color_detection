{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2541187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#from tqdm import tqdm\n",
    "#from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from data.base_dataset import Normalize_image\n",
    "from utils.saving_utils import load_checkpoint_mgpu\n",
    "\n",
    "from networks import U2NET\n",
    "import requests\n",
    "import extcolors\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "751df0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'put image directory'\n",
    "files = os.listdir(directory)\n",
    "device = 'cuda'\n",
    "checkpoint_path = 'cloth_segm_u2net_latest.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d265aad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_palette(num_cls):\n",
    "    \"\"\" Returns the color map for visualizing the segmentation mask.\n",
    "    Args:\n",
    "        num_cls: Number of classes\n",
    "    Returns:\n",
    "        The color map\n",
    "    \"\"\"\n",
    "    n = num_cls\n",
    "    palette = [0] * (n * 3)\n",
    "    for j in range(0, n):\n",
    "        lab = j\n",
    "        palette[j * 3 + 0] = 0\n",
    "        palette[j * 3 + 1] = 0\n",
    "        palette[j * 3 + 2] = 0\n",
    "        i = 0\n",
    "        while lab:\n",
    "            palette[j * 3 + 0] |= (((lab >> 0) & 1) << (7 - i))\n",
    "            palette[j * 3 + 1] |= (((lab >> 1) & 1) << (7 - i))\n",
    "            palette[j * 3 + 2] |= (((lab >> 2) & 1) << (7 - i))\n",
    "            i += 1\n",
    "            lab >>= 3\n",
    "    return palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81163f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save color result in csv\n",
    "transforms_list = []\n",
    "transforms_list += [transforms.ToTensor()]\n",
    "transforms_list += [Normalize_image(0.5, 0.5)]\n",
    "transform_rgb = transforms.Compose(transforms_list)\n",
    "\n",
    "net = U2NET(in_ch=3, out_ch=4)\n",
    "net = load_checkpoint_mgpu(net, checkpoint_path)\n",
    "net = net.to(device)\n",
    "net = net.eval()\n",
    "\n",
    "palette = get_palette(4)\n",
    "\n",
    "f = open('./result.csv','a', newline='')\n",
    "wr = csv.writer(f)\n",
    "z = 0\n",
    "\n",
    "def run():\n",
    "    for j,i in enumerate(files):\n",
    "\n",
    "        print(j)\n",
    "        try:\n",
    "            img = Image.open(\"./fw_2022/{}\".format(i))\n",
    "            img_size = img.size\n",
    "        except:\n",
    "            print(\"error3\")\n",
    "            continue\n",
    "        try:\n",
    "            re_img = img.resize((768, 768), Image.BICUBIC)\n",
    "            image_tensor = transform_rgb(re_img)\n",
    "            image_tensor = torch.unsqueeze(image_tensor, 0)\n",
    "            output_tensor = net(image_tensor.to(device))\n",
    "            output_tensor = F.log_softmax(output_tensor[0], dim=1)\n",
    "            output_tensor = torch.max(output_tensor, dim=1, keepdim=True)[1]\n",
    "            output_tensor = torch.squeeze(output_tensor, dim=0)\n",
    "            output_tensor = torch.squeeze(output_tensor, dim=0)\n",
    "            output_arr = output_tensor.cpu().numpy()\n",
    "        except:\n",
    "            print(\"error1\")\n",
    "            continue\n",
    "        output_img = Image.fromarray(output_arr.astype('uint8'), mode='L')\n",
    "        output_img = output_img.resize(img_size, Image.BICUBIC)\n",
    "        \n",
    "        output_img.putpalette(palette)\n",
    "        \n",
    "        img_arr = np.array(output_img.resize((500,700)))\n",
    "        mask = img_arr > 0\n",
    "        image_array = np.array(img.resize((500,700)))\n",
    "        try:\n",
    "            PIL_image = Image.fromarray(image_array[mask].reshape(1,-1,3)).convert('RGB')\n",
    "        except:\n",
    "            print(\"error2\")\n",
    "            continue\n",
    "        colors, pixel_count = extcolors.extract_from_image(PIL_image)\n",
    "        color_dict = OrderedDict()\n",
    "        for c in colors:\n",
    "            color_dict[\"{},{},{}\".format(c[0][0],c[0][1],c[0][2])] = round((c[1] / pixel_count) * 100, 2)\n",
    "        color_rgb = json.dumps(color_dict)\n",
    "        wr.writerow([i,color_rgb])\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db92cce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfc71b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv to dict\n",
    "color_dict = {}\n",
    "color_dict[\"result\"] = []\n",
    "for i in colordf.iloc:\n",
    "    small_dict = {}\n",
    "    small_dict[\"name\"] = i[\"image_name\"]\n",
    "    small_dict[\"RGB\"] = eval(i[\"color_result\"])\n",
    "    color_dict[\"result\"].append(small_dict)\n",
    "with open('./color_result.json'.format(file_name), 'a', encoding=\"utf-8\") as make_file:\n",
    "    json.dump(color_dict, make_file, ensure_ascii=False, indent=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "transformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
